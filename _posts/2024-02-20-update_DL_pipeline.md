---
layout: single
title:  "ë”¥ëŸ¬ë‹, ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ì—…ë°ì´íŠ¸"
categories: Code
tag: [PyTorch, PyTorch-Lightning, Hydra-core, WandB, Optuna, LightGBM, XGBoost]
toc: true
author_profile: false
sidebar:
    nav: "docs"
search: true
typora-root-url: ../
---



#  ì—…ë°ì´íŠ¸ ê³„ê¸°

ğŸ‘‰ğŸ»[ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ê¹ƒí—ˆë¸Œ 1](https://github.com/DimensionSTP/multimodal-transformer "ì²˜ìŒìœ¼ë¡œ êµ¬ì¡°í™”í•œ ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸")

ğŸ‘‰ğŸ»[ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ ê¹ƒí—ˆë¸Œ 2](https://github.com/DimensionSTP/rppg-project "ì„ì‚¬ í•™ìœ„ ì—°êµ¬ ê´€ë ¨ ë”¥ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸")



ì—…ë°ì´íŠ¸ëŠ” ëì´ ì—†ë‹¤. íŒŒì´í”„ë¼ì¸ ì—…ë°ì´íŠ¸ ì´í›„, model parallel strategy ë“±ì„ ê³µë¶€í•˜ë©° ìƒˆë¡œìš´ ì‚¬í•­ë“¤ì„ êµ¬í˜„í•˜ê³ , ê¸°ì¡´ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ì‹¶ì–´ì¡Œë‹¤.

í° ì¤„ê¸°ë¡œ ì•„ë˜ ì‚¬í•­ë“¤ì„ êµ¬í˜„, í˜¹ì€ í•´ê²°í•˜ê³  ì‹¶ì—ˆë‹¤.



__ëª©í‘œ__

+ DeepSpeed strategyì˜ ì„±ëŠ¥ì„ ìµœëŒ€í•œ ëŒì–´ë‚¼ ìˆ˜ ìˆëŠ” optimization
+ DeepSpeed strategyì™€ ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ì˜ ì™„ë²½í•œ í˜¸í™˜
+ Optunaë¥¼ ì´ìš©í•œ hyper-parameters tuningì—ì„œ multi-GPU ì‚¬ìš©
+ Training resumption
+ ë” ë‚˜ì€ WandB projects ê´€ë¦¬(ì‹¤í—˜ì´ ë„ˆë¬´ ë§ì´ ìŒ“ì´ë‹ˆ ì°¾ì•„ë³´ê¸° í˜ë“¦)

 

# íŒŒì´í”„ë¼ì¸ ì—…ë°ì´íŠ¸

íŒŒì´í”„ë¼ì¸ì˜ ëŒ€ë¶€ë¶„ì„ ì—…ë°ì´íŠ¸í•´ì•¼ í–ˆë‹¤.



+ LightningModuleì—ì„œ configure_optimization methodì—ì„œ DeepSpeedë¥¼ ìœ„í•œ optimizer ì„¤ì •

+ Tunerì—ì„œ Multi-GPUë¥¼ ì§€ì›í•˜ì§€ ì•ŠëŠ” Optuna integrationì˜ PyTorchLightningPruningCallback ì œê±° ë° early stop callback ì¶”ê°€
+ Pipelineì—ì„œ Training resumption ê¸°ëŠ¥ ì¶”ê°€
+ Pipelineì—ì„œ DeepSpeed Stage 3ì˜ ê²½ìš° inference ì‹œ single checkpoint fileì´ ì•„ë‹ˆë©´ ë°œìƒí•˜ëŠ” ì—ëŸ¬ í•´ê²°
+ Tunerì—ì„œ Callback, Trainerì™€ ì¤‘ë³µë˜ëŠ” configsë“¤ì„ ì‚¬ìš©í•˜ë¯€ë¡œ main configë¡œ unification
+ Checkpoint ê²½ë¡œ ë° ëª…ëª… ë°©ì‹, Logging projectì˜ modeë³„ ë¶„ë¦¬ë¥¼ ìœ„í•œ main config ìˆ˜ì •
+ ìœ„ ì‚¬í•­ì— ë”°ë¥¸ config íŒŒì¼ë“¤ ìˆ˜ì •
+ ê¸°íƒ€ ë ˆê±°ì‹œ ì—…ë°ì´íŠ¸



## ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬

ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „(python==3.8.x)

hydra-core==1.3.2

omegaconf==2.3.0

lightning==2.2.0

torch==2.2.0

wandb==0.16.3

optuna==3.5.0

deepspeed==0.13.1



## DeepSpeed Optimization

DeepSpeedì˜ ê²½ìš°, offload(GPU memoryë¥¼ ë”ìš± ì•„ë¼ê¸° ìœ„í•´ CPU ìµœì í™”ëœ optimizer ì‚¬ìš©, GPU-optimizerë³´ë‹¤ëŠ” ëŠë¦¼) ì˜µì…˜ì—ì„œ CPU ìµœì í™”ëœ Adam optimizerë¥¼ ì œê³µí•˜ë©°, ê¸°ë³¸ torchì˜ Adam or AdamW ëŒ€ë¹„ ì†ë„ê°€ ê½¤ ì°¨ì´ë‚œë‹¤.

ë˜í•œ, DeepSpeed stage 3ì˜ ê²½ìš° FusedAdam, offload ì‹œ CPUAdamì„ ì‚¬ìš©í•  ê²ƒì„ ê¶Œì¥í•˜ê³  ìˆìœ¼ë¯€ë¡œ í•´ë‹¹ ì¡°ê±´ì„ ë°˜ì˜í–ˆë‹¤.



![configure_optimizer](/images/2024-02-20-update_DL_pipeline/configure_optimizer.png){: .align-center}



## Multi-GPU Hparams Tuning

í™•ì¸ ê²°ê³¼, Optunaì˜ PyTorchLightningPruningCallbackì€ Multi-GPU(DDP)ê°€ ì ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤.

Multi-GPU ì„œë²„ì—ì„œ GPU í•œì¥ ì‚¬ìš©ì´ë¼ë‹ˆ, ì´ ë¬´ìŠ¨ ì†í•´ì¸ê°€? ì°¨ë¼ë¦¬ Pruning callbackì„ ì“°ì§€ ì•ŠëŠ” ê²ƒì´ ë‚«ë‹¤.

ë˜í•œ hparams studyì— ë”°ë¼ ëª¨ë¸ í•™ìŠµ ë° capacityì— ëŒ€í•œ parametersê°€ ë³€í•˜ëŠ”ë° ê³ ì • epochë¥¼ ì“´ë‹¤ëŠ” ê²ƒ ë˜í•œ ì‹œê°„ì  ì†í•´ë¼ì„œ, early stopì„ ì¶”ê°€í–ˆë‹¤.



![tuner_py](/images/2024-02-20-update_DL_pipeline/tuner_py.png){: .align-center}



## Pipeline Module Update

Pipelineì—ì„œëŠ” Training Resumption, DeepSpeed í˜¸í™˜ 2ê°€ì§€ ê¸°ëŠ¥ì„ ì¶”ê°€í–ˆë‹¤.



### Training Resumption

ìƒê°í•´ë³´ë‹ˆ Trainingì— ê¸°ì¡´ í•™ìŠµ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì™€ì„œ í•™ìŠµí•˜ëŠ” wrappingì„ í•˜ì§€ ì•Šì•˜ë‹¤.

ë”°ë¼ì„œ, main config íŒŒì¼ì— ì˜µì…˜ì„ ì¶”ê°€í•˜ê³  í•´ë‹¹ ì˜µì…˜ì— ë”°ë¼ training resumption ì—¬ë¶€ ë° ë‹¨ê³„ë¥¼ ê²°ì •í•˜ë„ë¡ í–ˆë‹¤.

Resumption ì‹œ PyTorch Lightningì—ì„œ ë‹¨ìˆœ model parameters, gradients, optimizer states ë¿ë§Œ ì•„ë‹ˆë¼, ì´ì „ epoch ì§„í–‰ ì •ë„ë„ ë¶ˆëŸ¬ì˜¤ê¸° ë•Œë¬¸ì—, epoch ê¸°ë°˜ìœ¼ë¡œ model checkpointë¥¼ ì €ì¥í•´ë„ ì¤‘ë³µì´ ì¼ì–´ë‚˜ì§€ ì•Šì•˜ë‹¤.



![training_resumption](/images/2024-02-20-update_DL_pipeline/training_resumption.png){: .align-center}



### DeepSpeed Strategy at Inference

DeepSpeed stage 3ì˜ ê²½ìš° trainingì—ì„œëŠ” ë¬¸ì œê°€ ë˜ì§€ ì•Šìœ¼ë‚˜, inference ì‹œ rankë³„ë¡œ í©ì–´ì§„ model parametersë¥¼ í•©ì³ì§„ íŒŒì¼ë¡œ í•˜ì§€ ì•Šìœ¼ë©´ ì—ëŸ¬ë¥¼ ë±‰ëŠ” ë¬¸ì œê°€ ìˆë‹¤.

PyTorch Lightningì—ì„œ load checkpointë¡œ DeepSpeedì˜ load checkpointë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë°, offload ì˜µì…˜ ì—¬ë¶€ê°€ ë¹ ì ¸ì„œ if ë¶„ê¸°ë¬¸ì—ì„œ ì´ìƒí•œ ê³³ìœ¼ë¡œ ë¹ ì ¸ ì—ëŸ¬ë¥¼ ë‚´ëŠ” ê²ƒ ê°™ì•˜ë‹¤.



![deepspeed_src](/images/2024-02-20-update_DL_pipeline/deepspeed_src.png){: .align-center}



ë”°ë¼ì„œ, DeepSpeed stage 3ë¡œ í•™ìŠµ ì‹œ, í•™ìŠµì´ ì¢…ë£Œë˜ë©´ í•´ë‹¹ ê²½ë¡œì˜ *model.pt*ë¡œ model parametersë¥¼ í•©ì³ì£¼ê³ , inference ì‹œì—ëŠ” í•©ì¹œ íŒŒì¼ì„ DDP strategyë¡œ ë¶ˆëŸ¬ì˜¤ë„ë¡ í–ˆë‹¤.



![deepspeed_train_end](/images/2024-02-20-update_DL_pipeline/deepspeed_train_end.png){: .align-center}



![deepspeed_test1](/images/2024-02-20-update_DL_pipeline/deepspeed_test1.png){: .align-center}



![deepspeed_test2](/images/2024-02-20-update_DL_pipeline/deepspeed_test2.png){: .align-center}



## Configs Update

ìœ„ êµ¬í˜„ ì‚¬í•­ë“¤ì— ë§ê²Œ .yaml configsë„ ì—…ë°ì´íŠ¸ í•´ì¤¬ë‹¤.



ë¨¼ì € callback, trainer, tunerì˜ module_paramsë¥¼ ê³µí†µì ìœ¼ë¡œ ì‚¬ìš©í•´ì„œ ë‹¤ main config fileë¡œ ëºë‹¤.

ë¿ë§Œ ì•„ë‹ˆë¼, logì—ì„œ stratgyì— ë”°ë¥¸ êµ¬ë¶„ì„ ë„£ì—ˆê³ , LightningModuleì—ì„œë„ configure_optimizerì˜ ë¶„ê¸°ë¥¼ strategyë¡œ ì²˜ë¦¬í•´ì•¼ í•˜ë‹ˆ ë”ë”ìš± ê·¸ë˜ì•¼ í–ˆë‹¤.

ê·¸ ì™¸, loggingì—ì„œ train, test, tune mode êµ¬ë¶„, strategy ì¶”ê°€, checkpointì—ì„œ strategy ì¶”ê°€, model parametersë¥¼ í´ë”ë¡œ ë‘ê³ , epochë§Œ checkpoint íŒŒì¼ ì´ë¦„ìœ¼ë¡œ í•˜ì—¬ ê°€ë…ì„±ì„ ë†’ì´ê³ , ê° ì‹¤í—˜ì— ëŒ€í•´ ë¶„ë¦¬ê°€ ê°€ëŠ¥í•˜ë„ë¡ í–ˆë‹¤.



![main_config](/images/2024-02-20-update_DL_pipeline/main_config.png){: .align-center}



![callback_config](/images/2024-02-20-update_DL_pipeline/callback_config.png){: .align-center}



![trainer_config](/images/2024-02-20-update_DL_pipeline/trainer_config.png){: .align-center}



![tuner_config](/images/2024-02-20-update_DL_pipeline/tuner_config.png){: .align-center}



![logger_config](/images/2024-02-20-update_DL_pipeline/logger_config.png){: .align-center}



## ETC

+ DataLoaderì—ì„œ ëª¨ë“  í”„ë¡œì íŠ¸ì—ì„œ train, val, test êµ¬ë¶„ì„ ëª¨ë‘ split ì˜µì…˜ìœ¼ë¡œ í†µì¼í•˜ê³ , ê¸°ë³¸ ì˜µì…˜ì„ split.trainìœ¼ë¡œ ì„¤ì •
+ LightningModule configì—ì„œ DeepSpeedì— ë”°ë¥¸ optimizer ë³€ê²½ì„ ìœ„í•œ strategy ì˜µì…˜ ì¶”ê°€
+ README ì—…ë°ì´íŠ¸
+ Shell scripts ì—…ë°ì´íŠ¸



# í›„ê¸°

ì™œ tagë¥¼ ë¶™ì´ê³ , versionì„ ì—…ë°ì´íŠ¸í•˜ëŠ”ì§€ ì•Œê² ë‹¤.

ë³¸ê²©ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê³ ì í•˜ë©´ ì—…ë°ì´íŠ¸ê°€ ëì´ ì—†ë‹¤.

ì›ë˜ ê°ê¸° ë‹¤ë¥¸ í™˜ê²½(version 1.x, 2.x)ì— ëŒ€í•´ ëª¨ë‘ í•´ë‹¹ ìš”êµ¬ ì‚¬í•­ì„ ì—…ë°ì´íŠ¸í•˜ë ¤ê³  í–ˆëŠ”ë°, ì¼ì´ ë„ˆë¬´ ë§ì•„ì ¸ì„œ ê°€ì¥ ìµœê·¼ ë²„ì „ë§Œ ì—…ë°ì´íŠ¸í–ˆë‹¤.

ì™œ ì—¬ëŸ¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì´ ì§ì „ ë²„ì „ì— ëŒ€í•œ ì—…ë°ì´íŠ¸ë§Œ ì§„í–‰í•˜ëŠ”ì§€ ê¹¨ë‹¬ì•˜ë‹¤.

í”„ë¡œì íŠ¸ë„ ì´ì œ ì—¬ëŸ¬ ê°œë¥¼ í•œë²ˆì— ì—…ë°ì´íŠ¸ë¥¼ í•˜ë ¤ë‹ˆ ê³µìˆ˜ê°€ ê½¤ ë§ì´ ë“ ë‹¤.

ìƒˆë¡œìš´ í”„ë¡œì íŠ¸ ì‹œì‘ ì‹œ DLì˜ ê²½ìš° ê¸°ì¡´ í”„ë¡œì íŠ¸ë¥¼ ê°€ì ¸ì˜¨ í›„ ì•„ë˜ ì‚¬í•­ë“¤ë§Œ ìˆ˜ì •í•˜ë©´ ëœë‹¤.

__Src__

+ Model structure ë° Custom loss function, optimizer, metric(í•„ìš” ì‹œ)
+ Dataset class ë° Collate_fn(í•„ìš” ì‹œ)
+ Modelì— ë”°ë¥¸ Architectureì„¸ë¶€ ë‚´ìš©
+ Modelì— ë”°ë¥¸ Tuner ì„¸ë¶€ ë‚´ìš©

__Configs__

+ Main config
+ Architecture ë° Dataset config
+ Callbacks configì˜ monitor ë° tracking_direction
+ Tuner config

ê·¸ëŸ¬ë‹ˆ í…œí”Œë¦¿ì„ ë§Œë“¤ì–´ í…œí”Œë¦¿ë§Œ ì—…ë°ì´íŠ¸ í•˜ë“ , ì§ì „ í”„ë¡œì íŠ¸ë§Œ ì—…ë°ì´íŠ¸ í›„ í•´ë‹¹ í…œí”Œë¦¿ í˜¹ì€ í”„ë¡œì íŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ ì‹ ê·œ í”„ë¡œì íŠ¸ì˜ ê¸°ë°˜ìœ¼ë¡œ ì‚¼ëŠ” ê²ƒì´ ë‚˜ì„ ê²ƒ ê°™ë‹¤.

ì„¸ë¶€ êµ¬í˜„ì— ëŒ€í•´ì„œëŠ” ë” ì´ì „ ê²ƒ ì¤‘ì— í•„ìš”í•œ ê²ƒì„ ì°¸ê³ í•˜ë©´ ë  ê²ƒì´ê³ , í”„ë¡œì íŠ¸ê°€ ìŒ“ì´ë‹¤ ë³´ë©´, ìì£¼ ì“°ëŠ” êµ¬í˜„ êµ¬ì¡°ë“¤ì€ ë”°ë¡œ ì •ë¦¬í•´ë‘¬ë„ ì¢‹ì„ ê²ƒ ê°™ë‹¤.