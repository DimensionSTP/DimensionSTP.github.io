---
layout: single
title: "Any-to-Any: Autoregressive Image Generation"
categories: Study-concept
tag: [Janus, GPT4o, Autoregrssive, Auto-Regressive, Image Generation, Native Image Generation, DeepSeek, OpenAI]
toc: true
author_profile: false
sidebar:
    nav: "docs"
search: true
typora-root-url: ../
---





# 0. Introduction

ğŸ‘‰ğŸ»[Janus paper link](https://arxiv.org/pdf/2410.13848v1)

ğŸ‘‰ğŸ»[Janus GitHub link](https://github.com/deepseek-ai/Janus)

ğŸ‘‰ğŸ»[Janus model link](https://huggingface.co/deepseek-ai/Janus-Pro-7B)

ğŸ‘‰ğŸ»[Janus blog link](https://blog.openvino.ai/blog-posts/deepseek-janus-pro-model-enabling-with-openvino#:~:text=Figure%201%20shows%20the%20architecture,the%20input%20space%20of%20LLM)

ğŸ‘‰ğŸ»[Janus review link](https://adithyabandara.medium.com/deepseek-janus-pro-7b-a-comprehensive-technical-analysis-of-the-multimodal-powerhouse-eb6243d4bc83#:~:text=match%20at%20L174%20,customization%20for%20niche%20use%20cases)

ğŸ‘‰ğŸ»[OpenAI introduction link](https://openai.com/index/introducing-4o-image-generation/)

ğŸ‘‰ğŸ»[OpenAI report link](https://cdn.openai.com/11998be9-5319-4302-bfbf-1167e093f1fb/Native_Image_Generation_System_Card.pdf#:~:text=2,generation%20to%20take%20one%20or)

ğŸ‘‰ğŸ»[OpenAI review link](https://aman.ai/primers/ai/gpt4o-native-image-generation/#:~:text=,a%20result%2C%20Transfusion%20significantly%20outperforms)

ğŸ‘‰ğŸ»[OpenAI news link](https://www.infoq.com/news/2025/04/gpt-4o-images/#:~:text=method)



> **"í† í°ì„ ì“°ë“¯ í”½ì…€ì„ ì“´ë‹¤." â€” Autoregressive Vision**



Stable Diffusionì´ ë¶ˆëŸ¬ì˜¨ í˜ì‹ ì€ modality transferë¥¼ ê°€ì†í–ˆì§€ë§Œ, ë…¸ì´ì¦ˆ ë°˜ë³µ 40-100 step ê³¼ latent-decode bottleneck ì´ë¼ëŠ” ê³ ì§ˆì  í•œê³„ë¥¼ ë‚¨ê²¼ë‹¤. 2025ë…„ ì´ˆ DeepSeek Janus-Pro ì™€ OpenAI GPT-4o ê°€ ì´ë¥¼ ì •ë©´ìœ¼ë¡œ ëŒíŒŒí•˜ë©° ë‹¤ì‹œ í•œ ë²ˆ íŒ¨ëŸ¬ë‹¤ì„ ì „í™˜ì„ ì´‰ë°œí–ˆë‹¤.



ë³¸ ê¸€ì€ ë‹¤ìŒ ì§ˆë¬¸ì— ë‹µí•œë‹¤.

- **Janus-Pro**ê°€ êµ¬í˜„í•œ **Unified Autoregressive Transformer** êµ¬ì¡°ëŠ” ë¬´ì—‡ì¸ê°€?

- **GPT-4o**ê°€ ë³´ì—¬ì¤€ "Blur â†’ Sharp" ìŠ¤íŠ¸ë¦¬ë°ì€ ì–´ë–¤ ë‚´ë¶€ íŒŒì´í”„ë¼ì¸ì—ì„œ ë¹„ë¡¯ë˜ë‚˜?

- ì „í†µì ì¸ **Latent Diffusion**ê³¼ ë‹¬ë¦¬ **patch-level denoising**ì´ ì™œ ì¤‘ìš”í•œê°€?

- Text Â· Code Â· Vision Â· Audioë¥¼ **Any-to-Any** ë¡œ í†µí•©í•  ë•Œ ARì´ ê°–ëŠ” ì••ë„ì  ì´ì ì€?



â–¶ Deep Dive

ì—°êµ¬ì‚¬ : 2023 T2I-Adapter, 2024 Chameleonì´ "Patch-AR" ì‹œë„ëŠ” í–ˆìœ¼ë‚˜ ì‹¤ì„œë¹„ìŠ¤ë¡œ ì´ì–´ì§€ì§€ ëª»í–ˆë‹¤. 2025 1Q ê¸°ì¤€, ìƒìš© ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ì—ì„œ ì‹¤ì‹œê°„ ì´ë¯¸ì§€ë¥¼ ìƒì„±Â·ìŠ¤íŠ¸ë¦¬ë°í•œ ì‚¬ë¡€ëŠ” GPT-4oê°€ ìµœì´ˆë‹¤. Janus-ProëŠ” ì†ŒìŠ¤ ê³µê°œ ì¸¡ë©´ì—ì„œ ì˜¤í”ˆì†ŒìŠ¤ ìƒíƒœê³„ì— ë” í° ì˜ë¯¸ë¥¼ ê°–ëŠ”ë‹¤.



# 1. Janus Model Overviews



## 1-1. Model Architecture

| Block                 | Role                         | Implementation Point            |
| --------------------- | ---------------------------- | ------------------------------- |
| **Shared AR Decoder** | Prediction of all modalities | 80-ë ˆì´ì–´, Rotary PE, 7B params  |
| Vision Encoder        | Image â†’ CLIP tokens          | ViT-L/14 ì¬ì‚¬ìš©                  |
| Image Tokenizer       | dVAE 32Â² / 8192 codebook     | í•™ìŠµ ì¤‘ VQGAN ì¬í›ˆë ¨              |
| Mix-In Adapter        | Any â†” Any êµì°¨                | Token-type embedding + gating   |



ğŸ“Œ *Janus Architecture*

![Janus-Architecture](/images/2025-04-21-Autoregressive-Image-Generation/Janus-Architecture.jpg){: .align-center}



> **Points** 
>
> - CLIP-Encoderì™€ dVAE-Tokenizerë¥¼ ë¶„ë¦¬í•´ "ì´í•´"ì™€ "ìƒì„±" ë‹´ë‹¹ì„ boolean-likeë¡œ ë¶„í• í•œë‹¤. 
> - Dual Pipe ë•ë¶„ì— Decoder-Only Transformerê°€ ì¶©ëŒ ì—†ì´ ì–‘ë°©í–¥ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤.



â–¶ **Deep Dive**

- **Shared Decoder** ëŠ” Text Â· Vision tokensë¥¼ ê°™ì€ positional spaceì— projectí•œë‹¤. ì´ë•Œ "gated cross-residual" ì„ ì‚¬ìš©í•´ ëª¨ë‹¬ íŠ¹ì´ íŒ¨í„´(ì˜ˆ: í”½ì…€ frequency)ì„ ì–µì œí•˜ê³ , attention head Î» ë¥¼ ë™ì ìœ¼ë¡œ ì¡°ì •í•œë‹¤.
- **dVAE Tokenizer** ëŠ” *vector-quantised* latentsë¥¼ 8192-way codebookìœ¼ë¡œ ì •ì œí•œë‹¤. Janus ë…¼ë¬¸ ë¶€ë¡ B.3ì— ë”°ë¥´ë©´ codebook collapseë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ Exponential Moving Average(EMA) ì—…ë°ì´íŠ¸ë¥¼ ì‚¬ìš©í•œë‹¤.
- **Mix-In Adapter** ëŠ” "Conditional LoRA" ì™€ ìœ ì‚¬ â€” W_q Â· W_k ì‚¬ì´ì— rank-4 linear ë¥¼ ì‚½ì…í•´ ëª¨ë‹¬ ì „í™˜ì‹œ residual pathë¥¼ ë¯¸ì„¸í•˜ê²Œ ì¡°ì ˆí•œë‹¤.



## 1-2. Train Method

-  **Single CE Loss** : Full sequenceë¥¼ í•˜ë‚˜ì˜ likelihoodë¡œ í•™ìŠµ

- **PromptÂ·Reroll loop** : Text LMì„ ì´ìš©í•´ in-house synthetic image-text pair 72Mê°œë¡œ í™•ì¥

-  **Balanced Sampling** : Text : Image : Mixed = 2 : 2 : 1ë¡œ DataLoader ê· í˜• ìœ ì§€ 



ğŸ“Œ *Janus Train Method*

![Janus-Train.png](/images/2025-04-21-Autoregressive-Image-Generation/Janus-Train.png){: .align-center}



â–¶ **Deep Dive**

- *Prompt Engine* ì€ Janus ë‚´ë¶€ LLM(13B)ì„ ì‚¬ìš©í•´ caption Â· neg - prompt Â· style ë³€í˜•ì„ ìƒì„±í•œë‹¤. _Self-Critique RL* ë¡œ íŒ¨í„´ ë‹¤ì–‘ì„±ì„ ë†’ì´ê³  exposure bias ë¥¼ ì¤„ì˜€ë‹¤.
- **Mixed Pair**(batch)ëŠ” í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ í† í°ì„ êµì°¨ë¡œ ì„ì–´ Any-to-Any ëª©ì ìœ¼ë¡œ í•™ìŠµí•œë‹¤. ì´ëŠ” GPT-4oê°€ ê³µê°œí•œ "ì¡°ê±´ë¶€ ìŒ" ìˆ˜ì§‘ ë°©ì‹ê³¼ êµ¬ì¡°ì ìœ¼ë¡œ ë™ì¼í•˜ë‹¤.



## 1-3. Inference Flow

**user prompt -> tokens -> AR Decoder -> vision token ids -> dVAE -> RGB patches progressive refine**



- **Patch Streaming:** í† í°ë§ˆë‹¤ dVAE ë””ì½”ë“œë¥¼ ì¦‰ì‹œ í˜¸ì¶œí•´ "ì €í•´ìƒë„ â†’ ê³ í•´ìƒë„"ë¡œ ê°.

> ì‹¤í—˜ì ìœ¼ë¡œ 512Â² ì´ë¯¸ì§€ë¥¼ 2.7 sì— ìƒì„±(8xA100, FP8) â€” *Opened demo ê¸°ì¤€*.



â–¶ **Deep Dive**

- **KV Cache ì¬ì‚¬ìš©** : í…ìŠ¤íŠ¸ ìƒì„± ì´í›„, ë™ì¼ KV ë©”ëª¨ë¦¬ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê³  vision token branchë§Œ ì´ì–´ ë°›ì•„ ì†ë„ë¥¼ ëŒì–´ì˜¬ë¦°ë‹¤.
- **dVAE Refine** : ì´ˆê¸° 8Â² íŒ¨ì¹˜ê°€ í•´ìƒë„ 32Â²ê¹Œì§€ ë¹ ë¥´ê²Œ í™•ì¥ë˜ëŠ”ë°, dVAE decoderì˜ **shared up-conv** ë ˆì´ì–´ê°€ patch strideë¥¼ ì¤„ì´ë©° intermediate featuresë¥¼ ì¬í™œìš©í•œë‹¤.




# 2. GPT-4o Native Image Generation(presumption)



## 2-1. Full Pipeline(Include UpSampler)

| Stage                            | Module                           | Description                                             | Remark              |
| -------------------------------- | -------------------------------- | ------------------------------------------------------- | ------------------- |
| (A) **MultiModal Encoder**       | Text Â· Vision ì…ë ¥                | CLIP íŒŒìƒ                                               |                     |
| (B) **Autoregrssive Decoder**    | Decoder-Only Transformer(GPT 4o) | Sequence prediction of  **original resolution patches** |                     |
| (C) **Patch-wise Denoiser**      | Ïƒ ìŠ¤ì¼€ì¤„ ë‚´ì¥                      | Tokenë§ˆë‹¤ residual Î²-schedule ì ìš©                       |                     |
| (D) **Patch Upsampler** *(ì˜µì…˜)*  | SR MLP or Swin-IR                | **Denoisingê³¼ ë™ì‹œì—** 16Â² â†’ 32Â² upsampling              | Streaming Quality â†‘ |



*Case 1 : UpSampler ìƒëµ*

> AR Decoderê°€ 512Â² pixel patchë¥¼ ì§ì ‘ ì˜ˆì¸¡ â†’ Patch-wise Denoisier ì¢…ë£Œì™€ ë™ì‹œì— ìµœì¢… í•´ìƒë„ ì™„ì„±.

*Case 2 : UpSampler í¬í•¨*

> AR Decoder â†’ 16Â² token prediction â†’ **Patch-wise Denoisierê°€ Ïƒâ†“ì™€ SRâ†‘ë¥¼ í•œ ë²ˆì— ìˆ˜í–‰** â†’ ì¦‰ì‹œ 32Â² pixelë¡œ ì „ì†¡. ì´ì¤‘ íŒ¨ìŠ¤ ì—†ì´ "Blur â†’ Sharp" ë‹¨ê³„ êµ¬í˜„ ê°€ëŠ¥.

ì´ ë•Œë¬¸ì— ë°ëª¨ì—ì„œëŠ” **í† í°ì´ ë„ì°©í• ìˆ˜ë¡ ìƒ Â· ì¢Œ â†’ í•˜ Â· ìš°ë¡œ ì„ ëª…í™”**ë˜ëŠ” ëª¨ìŠµì´ ì¡í˜.ğŸ‘‰ğŸ»[Reference](https://www.linkedin.com/posts/leadgenmanthan_that-blurry-to-sharp-transition-in-gpt-4o-activity-7311309841069740032-R9cA/?utm_source=chatgpt.com)



â–¶ **Deep Dive â€“ Case Study**

- **Case 1 (UpSampler ì—†ìŒ)** : 16Â² patch â†’ denoise(Ïƒ â†˜) â†’ ì¦‰ì‹œ 512Â² pixel ì™„ì„±. ë°ëª¨ì—ì„œ 3-step íë¦¿ â†’ ì„ ëª… íŒ¨í„´ì´ 1s ì´ë‚´ë©´ ì´ ì¼€ì´ìŠ¤ì¼ ê°€ëŠ¥ì„±.
- **Case 2 (UpSampler í¬í•¨)** : 16Â² â†’ denoise + SR ë³‘ë ¬ â†’ 32Â² â†’ â€¦ ë‘ ë²ˆ ë°˜ë³µí•´ 1024Â². ìŠ¤íŠ¸ë¦¼ ë²„í¼ê°€ **ì¤‘ë³µ íŒ¨ì¹˜** ë¥¼ ìŠ¤í‚µí•˜ë©° ìì—°ìŠ¤ëŸ½ê²Œ ë¸”ë¡ë³„ í•´ìƒë„ë¥¼ ë†’ì¸ë‹¤.



## 2-2. Internal Analysis

- **ë”¥ëŸ¬ë‹ ì—…ìƒ˜í”Œ ë³‘í–‰** : Patchë‹¹ Ïƒ(t) ë¥¼ ìœ ì§€í•˜ë©´ì„œ SR LayerNormì„ ê³µìœ í•˜ë©´ ì¶”ê°€ latency < 8 ms.
- **ë©”ëª¨ë¦¬ íš¨ìœ¨** : Latent Diffusion(64 chan) ë³´ë‹¤ patch-denoise(3 chan) ê°€ peak VRAM â†“ 25 %.
- **í’ˆì§ˆ** : ìµœì¢… pixel spaceì—ì„œ denoiseí•˜ë¯€ë¡œ ê¸€ì”¨Â·ìœ ë¦¬ë°˜ì‚¬ ë“± ê³ ì£¼íŒŒ ë””í…Œì¼ ì†ì‹¤ ìµœì†Œí™”ğŸ‘‰ğŸ»[Reference](https://news.ycombinator.com/item?id=43474112&utm_source=chatgpt.com)
- **Patch Î²-Schedule** : Ïƒ(t) ë¥¼ patch idì™€ í•¨ê»˜ ì˜ˆì¸¡í•˜ëŠ” **2-D condition**. ì´ëŠ” Rolling Diffusionì„ patchë¡œ ë¶„í• í•œ í˜•íƒœì™€ ê°™ë‹¤.
- **Weight Sharing** : Denoiserì™€ Upsamplerê°€ Depth-wise Conv ì»¤ë„(+GroupNorm) ì„ ê³µìœ í•˜ë©´ ë§¤ patchë‹¹ ë§¤íŠ¸ë¦­ìŠ¤ ê³± ë¹„ìš©ì´ ì ˆë°˜ ì´í•˜.
- **ìŠ¤ë ˆë“œ ë³‘ë ¬ì„±** : 16Â² íŒ¨ì¹˜, 256-token íƒ€ì¼ ìƒì„± â†’ asyncio gRPC ë¡œ mux, ìµœì¢… ì •ë ¬ì€ client-side canvas.



# 3. AR vs Diffusion : Principle and Difference

â–¶ **Deep Dive â€“ ìˆ˜ì‹**

- **AR Likelihood** 
  $$
  \log P(x) = \sum_{t=1}^{T} \log P(x_t\mid x_{<t};\theta).
  $$
  Transformerì˜ causal mask ë•ë¶„ì— ëª¨ë“  ëª¨ë‹¬ì— ë™ì¼ ì ìš©.

- **DDPM Objective** 
  $$
  L_\text{simple} = \mathbb{E}_{t,x,\epsilon}
  \|\,\epsilon - \epsilon_\theta(\sqrt{\bar\alpha_t}x + \sqrt{1-\bar\alpha_t}\,\epsilon,t)\|^2.
  $$
  Ïƒ(t) ìŠ¤ì¼€ì¤„ ì¶”ì •ì´ í•„ìš”í•´ any-to-anyë¡œ í™•ì¥ ì‹œ modalityë§ˆë‹¤ Î²-scheduleì„ ë”°ë¡œ ì¡°ì •í•´ì•¼ í•œë‹¤.



## 3-1. Autoregressive Pipeline

1) dVAE or Tokenizer: Image â†’ Tokens

2) Autoregressive LM: $p(x_t \mid x_{<t})$

3) dVAE-Decode: Tokens â†’ RGB

4) (ì„ íƒ) Patch Denoise / SR

**ì „ì—­ ì´ì–´ì“°ê¸°** : Text Â· Pixel ëª¨ë‘ ë™ì¼ loss â†’ Multimodal Integrationì—ì„œ ë¬´ì†ì‹¤.



## 3-2. Latent Diffusion Pipeline

- 1) ì›ë³¸ RGB â†’ Latent $z$

- 2) ë°˜ë³µ Noise $t!!\downarrow$ â†’ $z_0$ ì˜ˆì¸¡

- 3) Latent â†’ RGB decode

- 4) (ì„ íƒ) UpSampler

**ì¥ì ** : ê¸€ë¡œë²Œ ì§ˆê°Â·ë¹›Â·ê·¸ë ˆì¸ í‘œí˜„.

**ì•½ì ** : Streaming ë¶ˆê°€, Any-to-Any í†µí•© ë‚œì´ë„, ë°˜ë³µ 40-100 step ì§€ì—°.



## 3-3. Patch side Diffusion(presumption)

> "Ïƒ scheduleì„ **Patch ID**ì™€ í•¨ê»˜ ì˜ˆì¸¡" â†’ Imageë¥¼ **Token ë‹¨ìœ„**ë¡œ denoise í•¨.
>
> ê²°ê³¼ì ìœ¼ë¡œ Diffusionì˜ ì§ˆê° + ARì˜ ì†ë„ë¥¼ ì ˆì¶©í•¨.



# 4. Janus vs GPT-4o



| Item        | **Janus-Pro-7B** | **GPT-4o Native**(ì˜ˆìƒ)  |
| ----------- | ---------------- | ----------------------- |
| Parameter   | 7B               | over 1T(ì¶”ì •)            |
| Tokenizing  | dVAE 8192        | **Patch 16Â²** ~ 16 K    |
| Decoder     | 80-L, RMSNorm    | >120-L, GQA             |
| Denoising   | dVAE Refine      | **Patch-Diffusion**     |
| Upsampling  | Swin-IR(ì„ íƒ)     | **ì˜µì…˜**, íŒ¨ì¹˜-ë™ì‹œ SR    |
| Streaming   | âœ”                | âœ” (Blur â†’ Sharp)        |
| Open source | ì½”ë“œ + ê°€ì¤‘ì¹˜      | API only                |



# 5. Any-to-Any Structure

â–¶ **Deep Dive â€“ Token Space ì„¤ê³„**

- **Modality Tokens (<img>, <aud>)** ì€ **relative-pos bucket** ë¥¼ ë³„ë„ë¡œ ê°–ëŠ”ë‹¤. ì´ëŠ” Visionì— íŠ¹í™”ëœ 2-D biasë¥¼ Text spaceì™€ ì„ì§€ ì•Šìœ¼ë ¤ëŠ” ì˜ë„.
- **ì—°ì† ë°ì´í„°(Audio Â· Sensor)** ëŠ” 1-D patch stride=2 or 4, RMSNorm ìœ¼ë¡œ ì •ê·œí™” í›„ ë™ì¼ AR spaceì— íˆ¬ì˜.



## 5-1. Input

- **Text: Byte-BPE**

- **Image: dVAE / Patch-Tokenizer**

- Audio: EnCodec (50) Hz tokens



## 5-2. Output

- `<txt>` `<img>` `<aud>` delimited sequence
- ìµœì¢… decoderëŠ” modalityë³„ Adapter í˜¸ì¶œ

> ìš”ì  : "Large Autoregressive-LM + modalityë³„ Encoder(Tokenizer)" == General Multimatorial System.



# 6. Comparison with Traditional Multimodal LLM

| Model              | Tokenizing | Any-to-Any | Streaming     | Denoising  |
| ------------------ | ---------- | ---------- | ------------- | ---------- |
| **GPT-4o**         | Patch AR   | âœ”          | **Real-time** | Patch-wise |
| Chameleon          | Patch AR   | âœ” (ì œí•œ)    | Experimental  | Latent     |
| LLaMA-3.2 + BLIP-2 | Cross-Attn | âœ–          | âœ–             | N/A        |



GPT-4oëŠ” **Patch-wise denoise + SR ì˜µì…˜**ìœ¼ë¡œ í’ˆì§ˆ Â· ì†ë„ë¥¼ ë™ì‹œì— í™•ë³´.



â–¶ **Deep Dive â€“ Chameleon vs 4o**

- Chameleonì€ **Pixel â†’ Latent â†’ AR** ë¡œ ë‹¤ì‹œ latentì— ì˜ì¡´, streaming latencyê°€ 4o ëŒ€ë¹„ 2â€“3 x í¬ë‹¤.
- GPT-4oëŠ” **Patch-AR** ë§Œìœ¼ë¡œë„ í”„ë¡¬í”„íŠ¸ ê°„ alignment loss ë¥¼ ì¶•ì í•´ *style consistency* ë¥¼ í™•ë³´í•œë‹¤.




# 7. Summary & Insights

- **Diffusion â†’ Auxiliary Stage**: ARê°€ í’ˆì§ˆ ê²©ì°¨ë¥¼ ë¹ ë¥´ê²Œ ì¤„ì´ë©° *ì‹¤ì‹œê°„* ê³¼ *ëª¨ë‹¬ í†µí•©* ì—ì„œ ìš°ìœ„ë¥¼ ì í–ˆë‹¤.
- **Any-to-Any Paradigm** : ê±°ëŒ€ AR-LM í•œ ê°œ + Tokenizer Adapter N ê°œ â†’ í…ìŠ¤íŠ¸ ë°– ì„¸ê³„ë¥¼ ìì—°ìŠ¤ë ˆ í™•ì¥.
- **Research Trend** : Patch Diffusion, Progressive Vocab Learning(UGen), Unified Token space(UniToken) ì—°êµ¬ ê¸‰ì¦ ğŸ‘‰ğŸ»[UGen](https://arxiv.org/html/2503.21193?utm_source=chatgpt.com), [UniToken](https://arxiv.org/html/2504.04423v1?utm_source=chatgpt.com).
- **Industrial Prospect** : ë¹…í…Œí¬ëŠ” Vision Â· Audio ë°ì´í„°ë¡œ RLHFë¥¼ ìˆ˜í‰ í™•ì¥, ì˜¤í”ˆ ì†ŒìŠ¤ ì§„ì˜ë„ Janusë¥¼ ë² ì´ìŠ¤ë¡œ patch diffusion benchmark ê²½ìŸì— í•©ë¥˜í•  ë“¯.



â–¶ **Deep Dive â€“ ì‚°ì—… ì‹œì‚¬ì **

- **Fine-Tuning ë¹„ìš©** : AR-IGëŠ” ì‹ ê·œ ëª¨ë‹¬ í•™ìŠµ ì‹œ tokenizerë§Œ ì¶”ê°€í•˜ë©´ ë˜ë¯€ë¡œ, diffusion ëŒ€ë¹„ **ìµœëŒ€ x3 ë°ì´í„° íš¨ìœ¨**(DeepSeek ë‚´ë¶€ ë³´ê³ ).
- **ëª¨ë¸-ì„œë¹™** : íŒ¨ì¹˜-AR ì€ *ë¹„ë™ê¸° tokenizer â†’ GPU AR core â†’ CPU dVAE* íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë‹¤ì¤‘ ëª¨ë‹¬ ë™ì‹œ ì²˜ë¦¬ ê°€ëŠ¥.
- **ì˜¤í”ˆì†ŒìŠ¤ ê³¼ì œ** : (1) Patch-Denoise ì•Œê³ ë¦¬ì¦˜ì˜ ê³µê°œ (2) íŒ¨ì¹˜ í† í° vocabularyì˜ í‘œì¤€í™” (3) ë¶„ì‚° KV-cache ê´€ë¦¬.



> **Insights** 
>
> - ëª¨ë¸ê³¼ ë°ì´í„°ê°€ ì¶©ë¶„íˆ í¬ë©´, *ì ì–´ë„ ì¶”ë¡  ì˜ì—­ì—ì„œëŠ”* ë””í“¨ì „ì¡°ì°¨ "íŒ¨ì¹˜-ë³´ì • íš¨ê³¼"ë¡œ AR ì‹œëŒ€ë¥¼ ë³´ì¡°í•˜ê²Œ ë  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤. **ì´ë¯¸ì§€ëŠ” ê³§ í…ìŠ¤íŠ¸ì²˜ëŸ¼ ì±„íŒ…ëœë‹¤.**
>
> - ì´ì œ ì´ë¯¸ì§€Â·ì˜¤ë””ì˜¤ê¹Œì§€ **"ì±„íŒ…"** í•˜ëŠ” ì‹œëŒ€. í¬ê³  ì˜ í•™ìŠµëœ AR-LM í•œ ëŒ€ë©´, ëª¨ë‹¬ í™•ì¥ì€ *Tokenizer plugin* ìˆ˜ì¤€ìœ¼ë¡œ ë‹¨ìˆœí™”ëœë‹¤.

