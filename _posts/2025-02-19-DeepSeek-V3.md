---
layout: single
title:  "DeepSeek-V3 Review"
categories: Study-concept
tag: [DeepSeek, DeepSeek-V3, MLA, MoE, MTP, Mixed-precision, Hopper architecture]
toc: true
author_profile: false
sidebar:
    nav: "docs"
search: true
typora-root-url: ../
---





#  DeepSeek-V3 Review

👉🏻[논문 링크](https://arxiv.org/abs/2412.19437 "DeepSeek V3") 

DeepSeek-V3에 대한 리뷰는 이미 많이 나왔다. 단순한 성능 비교나 벤치마크 결과를 나열하는 것은 의미가 없다고 생각한다.

대신, 이번 리뷰에서는 **최적의 성능을 끌어내는 트랜스포머 아키텍처의 설계와 효율적인 학습을 위한 혼합 정밀도 활용**에 집중하려 한다.

특히,

- 전통적인 디코더 기반 트랜스포머 모델을 어떤 기술들을 적용해서 **개선을 거듭**하여 전반적인 효율 및 성능을 향상시켰는지
- Nvidia Hopper Architecture를 최대한 활용한 **FP8 mixed precision**이 어떻게 성능은 유지하면서도 자원 및 시간을 절감시켰는지
- 기타 학습 hyper-parameters

이 세 가지 핵심 요소를 중심으로 분석해보려고 한다. DeepSeek-V3의 아키텍처와 학습 기법이 기존 모델과 어떤 차별점을 가지는지 살펴보자.



# Architectures

- DeepSeek V3의 아키텍처는 기존의 전통적인 디코더 기반 트랜스포머 모델 대비 3가지가 다름
  - MLA
    - MLA는 딥시크의 독자적 구조
  - MoE
    - MoE는 많이 존재해왓으나 딥시크만의 아이디어 첨가(auxiliary-loss free strategy, default top p)
  - MTP
    - MTP는 기존이나 메두사와 같이 LM head를 나누는게 아니라 lm head는 공유, 트랜스포머 블록에 재귀적으로 태우는 방식
    - 추론 모델링 코드에는 구현되어있지 않아서 구체적으로 알 수는 없음

시작





## Multi-head Latent Attention(MLA)

+ 딥시크만의 독자적 아키텍처
+ Q, K, V를 처음부터 lora 이용
+ K, V를 1개의 projection에서 뽑음
+ rope와 nope로 나눔
+ GQA, MQA 둘 다 활용(k head dim = 1 -> rope or nope)
+ 라마 어텐션 코드 캡처 추가
+ MLA 코드 캡처 추가
+ 라마 어텐션 피규어 추가
+ MLA 피규어 추가

시작



![MLA](/images/2025-02-19-DeepSeek-V3/deepseek-mla.png){: .align-center}





## Mixture of Experts(MoE)

- MoE는 기존에도 있었음
- 하지만 deepseek는 추가적인 아이디어 가미
- auxiliary-loss free strategy
- default top p
- 이렇게 했을 때 장점
- MoE 피규어 추가
- deepseek MoE 논문 수식 캡처 추가
- deepseek MoE 코드 캡처 추가

시작



👉🏻[DeepSeek MoE 논문 링크](https://arxiv.org/pdf/2401.06066 "DeepSeek MoE") 



![MoE](/images/2025-02-19-DeepSeek-V3/deepseek-moe.png){: .align-center}





## Multi-Token Prediction(MTP)

+ MTP는 train 단계에서 많이 쓰는 방법
+ 기존 MTP 방법론들 소개
+ 기존 MTP 피규어 캡처 추가
+ deepseek의 MTP 차별성 소개
+ deepseek MTP 피규어 캡처 추가
+ 이렇게 할 때 장점 설명
+ modeling deepseek는 추론 모델 구성이라 train은 알 수 없음, 그래서 구체적인 구현은 알 수 없음

시작



![MTP](/images/2025-02-19-DeepSeek-V3/deepseek-mtp.png){: .align-center}





# Mixed Precision

+ deepseek는 대중국 gpu 규제로 H100의 다운그레이드 버전인 H800만을 사용
+ H100 vs H800 비교 캡처 추가
+ 그러나 H800도 hopper 아키텍처임
+ 딥시크는 hopper 아키텍처의 특징인 fp8 혼합정밀도 최적화 방식을 최대한 활용

시작





## FP8 mixed precision

+ deepseek는 모델 학습, 중간 저장, 최종 저장에 fp8, bf16, fp32 모두 활용함
+ 이전 ampere 아키텍처 bf16 혼합 정밀도 설명
+ ampere 아키텍터 장점 캡처 추가
+ 기존 mixed precision 방식 설명
+ 기존 mixed precision 방식 캡처 추가
+ blackwell 이전 지금 가장 대중적인 hopper 아키텍처와 fp8 혼합 정밀도 설명
+ hopper 아키텍처 장점 캡처 추가
+ fp8 mixed precision 방식 설명
+ deepseek mixed precision 방식 캡처 추가(기존과 비교 하는 내용 추가 편집할 것)
+ 그래서 효율적으로 학습을 이뤄냄

시작



![mixed-precision](/images/2025-02-19-DeepSeek-V3/mixed-precision.png){: .align-center}



![backprop-0](/images/2025-02-19-DeepSeek-V3/backprop-0.png){: .align-center}



![backprop-1](/images/2025-02-19-DeepSeek-V3/backprop-1.png){: .align-center}



![backprop-2](/images/2025-02-19-DeepSeek-V3/backprop-2.png){: .align-center}



![backprop-3](/images/2025-02-19-DeepSeek-V3/backprop-3.png){: .align-center}



![backprop-4](/images/2025-02-19-DeepSeek-V3/backprop-4.png){: .align-center}



![backprop-5](/images/2025-02-19-DeepSeek-V3/backprop-5.png){: .align-center}



![backprop-6](/images/2025-02-19-DeepSeek-V3/backprop-6.png){: .align-center}



![backprop-7](/images/2025-02-19-DeepSeek-V3/backprop-7.png){: .align-center}



![deepseek-fp8](/images/2025-02-19-DeepSeek-V3/deepseek-fp8.png){: .align-center}



# Hyper-Parameters

+ deepseek의 단계별 모델 트레이닝 하이퍼 파라미터 정리
+ llama의 단계별 모델 트레이닝 하이퍼 파라미터와 비교
+ 인사이트 추가

시작



![deepseek-pretrain-hparams](/images/2025-02-19-DeepSeek-V3/deepseek-pretrain-hparams.png){: .align-center}



![deepseek-long-context-hparams](/images/2025-02-19-DeepSeek-V3/deepseek-long-context-hparams.png){: .align-center}



![deepseek-sft-hparams](/images/2025-02-19-DeepSeek-V3/deepseek-sft-hparams.png){: .align-center}





# 후기

+ deepseek v3를 리뷰하며 적은 자원 내에서 최대한 효율을 뽑아내려다보니 놀라운 연구 성과가 나타남
+ 기존의 잡기술들을 모두 사용하는 것을 넘어서 발전시킴
+ 물론 데이터에 대한 이슈는 있지만 기술의 발전에 기여한 것은 무시되어선 안됨
+ 하나하나 작은 잡기술들의 적용으로 인해 큰 산을 만들어냄
+ 기술도 예술도 큰 자본에서 규모적 발전을 이뤄낸다면, 결핍에서는 혁신을 이뤄낸다

시작

