---
layout: single
title:  "LLM Train Recipe"
categories: Study-concept
tag: [LLM, Train Recipe, Tulu, SmolLM2, Dataset, Fine-tuning]
toc: true
author_profile: false
sidebar:
    nav: "docs"
search: true
typora-root-url: ../
---





#  LLM Train Recipe

ğŸ‘‰ğŸ»[Tulu3 paper link](https://arxiv.org/pdf/2411.15124)

ğŸ‘‰ğŸ»[SmolLM2 paper link](https://arxiv.org/html/2502.02737v1)

ìµœê·¼ AI ì—°êµ¬ ì»¤ë®¤ë‹ˆí‹°ì—ì„œëŠ” ëª¨ë“  í•™ìŠµ ë°ì´í„°ì™€ íŒŒë¼ë¯¸í„°ë¥¼ íˆ¬ëª…í•˜ê²Œ ê³µê°œí•˜ëŠ” ëª¨ë¸ë“¤ì´ ì£¼ëª©ë°›ê³  ìˆë‹¤.
**TÃ¼lu 3**ëŠ” Llama 3.1 ê¸°ë°˜ì˜ post-trained modelsë¡œ, base ëª¨ë¸ì„ ê°€ì ¸ì™€ì„œ ì§€ë„í•™ìŠµ(SFT), Preference íŠœë‹(DPO), ê·¸ë¦¬ê³  (8B ëª¨ë¸ì— í•œì •í•œ) ê°•í™”í•™ìŠµ(RLVR) ë‹¨ê³„ë¥¼ í†µí•´ ì„±ëŠ¥ì„ ê·¹ëŒ€í™”í–ˆë‹¤.
**SmolLM2**ëŠ” Pre-trainingë¶€í„° Fine-tuningê¹Œì§€ ì „ ê³¼ì •ì„ ì˜¤í”ˆ ë°ì´í„°ë¡œ ì§„í–‰í•œ ëª¨ë¸ë¡œ, Pre-training ë°ì´í„°ì™€ Fine-tuning ë°ì´í„°ê°€ ëª¨ë‘ ê³µê°œë˜ì–´ ìˆëŠ” ì´ˆê²½ëŸ‰ ì˜ì–´ ëª¨ë¸ì´ë‹¤.
ë³¸ ë¦¬ë·°ì—ì„œëŠ” ë‘ ëª¨ë¸ì˜ ì£¼ìš” êµ¬ì„± ìš”ì†Œë¥¼ ì„¸ì„¸í•˜ê²Œ ì‚´í´ë³´ê³ , ê° ë‹¨ê³„ë§ˆë‹¤ dataset, method, hyper-parametersë¥¼ ë¹„êµí•´ ë³¸ë‹¤.



# Model Overviews

**TÃ¼lu 3**ì™€ **SmolLM2**ì˜ ëª¨ë¸ êµ¬ì¡°ì— ëŒ€í•´ ê°„ëµíˆ ì •ë¦¬í•´ë³¸ë‹¤.



## TÃ¼lu 3

- **Base models:**
  - Llama 3.1 ê¸°ë°˜
  - Model parameters: 8B, 70B, 405B

- **Key points:**

  - ìì²´ êµ¬ì¶•í•œ post-train datasetìœ¼ë¡œ SFT, DPO, RLVRì„ ë‹¨ê³„ë³„ë¡œ ì ìš©
  - ê° post-train ë‹¨ê³„ì—ì„œì˜ hyper-parameters ë° reconstruction script ê³µê°œ

  - ê° ë‹¨ê³„ë³„ë¡œ ì²´í¬í¬ì¸íŠ¸ê°€ ê³µê°œë˜ì–´ ìˆì–´, ì—°êµ¬ìë“¤ì´ ì‰½ê²Œ ì¬í˜„ ë° í™•ì¥ì´ ê°€ëŠ¥



## SmolLM2

- **Base models:**
- Llama(>3.1) Architectures ê¸°ë°˜
  - Model parameters: 135M, 360M, 1.7B
  - Pre-trainë¶€í„° ì§„í–‰

- **Key points:**
  - ìì²´ êµ¬ì¶•í•œ pre-train, post-train datasetìœ¼ë¡œ í•™ìŠµ
  - ê° í•™ìŠµ ë‹¨ê³„ì—ì„œì˜ hyper-parameters ê³µê°œ




# Data Overviews

**TÃ¼lu 3**ì™€ **SmolLM2**ì˜ í•™ìŠµ ë°ì´í„°ì…‹ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤.



## TÃ¼lu 3

- **Supervised Fine-Tuning (SFT) ë°ì´í„°:**
  - ê³µê°œ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ ë°ì´í„°ì…‹ê³¼ synthetic ë°ì´í„°ì˜ í˜¼í•©
  - ë‹¤ì–‘í•œ íƒœìŠ¤í¬(ëŒ€í™”, ìˆ˜í•™, ì½”ë”©, ì•ˆì „ì„± ë“±)ë¥¼ í¬í•¨
  - ğŸ‘‰ğŸ»[allenai/tulu-3-sft-mixture](https://huggingface.co/datasets/allenai/tulu-3-sft-mixture)

- **Preference Tuning(DPO) ë°ì´í„°:**
  - SFT ë‹¨ê³„ì˜ ì¶œë ¥ê³¼ íƒ€ ëª¨ë¸ì˜ ì‘ë‹µì„ ë¹„êµí•˜ì—¬ êµ¬ì„±ëœ on-policy ë°ì´í„°
  - ğŸ‘‰ğŸ»[allenai/llama-3.1-tulu-3-405b-preference-mixture](https://huggingface.co/datasets/allenai/llama-3.1-tulu-3-405b-preference-mixture)
  - ğŸ‘‰ğŸ»[allenai/llama-3.1-tulu-3-70b-preference-mixture](https://huggingface.co/datasets/allenai/llama-3.1-tulu-3-70b-preference-mixture)
  - ğŸ‘‰ğŸ»[allenai/llama-3.1-tulu-3-8b-preference-mixture](https://huggingface.co/datasets/allenai/llama-3.1-tulu-3-8b-preference-mixture)

- **RLVR(PPO) ë°ì´í„° (8B ëª¨ë¸ ì „ìš©):**
  - GSM8K, MATH, IFEval ë“± â€œê²€ì¦ ê°€ëŠ¥í•œ ì •ë‹µâ€ ì—¬ë¶€ì— ë”°ë¥¸ ë³´ìƒ ì²´ê³„ ë°ì´í„°
  - ğŸ‘‰ğŸ»[allenai/RLVR-GSM-MATH-IF-Mixed-Constraints](https://huggingface.co/datasets/allenai/RLVR-GSM-MATH-IF-Mixed-Constraints)



## SmolLM2

- **Pre-training ë°ì´í„°:**

  - ì›¹ í¬ë¡¤ ë°ì´í„°(ì˜ˆ: CommonCrawl, ë‰´ìŠ¤, ë¸”ë¡œê·¸) ë° ìœ„í‚¤í”¼ë””ì•„, ë„ì„œ, ë…¼ë¬¸ ë“±

  - ì•½ 11T tokensì˜ ì •ì œëœ ë°ì´í„°ë¥¼ í™œìš©

- **Supervised Fine-Tuning (SFT) ë°ì´í„°:**

  - ê³µê°œ ì¸ìŠ¤íŠ¸ëŸ­ì…˜ ë°ì´í„°ì™€ ìì²´ synthetic ë°ì´í„°ì˜ í˜¼í•©

  - í•„ìš”ì— ë”°ë¼ ì˜¨-í´ë¦¬ì‹œ ë°©ì‹ì˜ Preference ë°ì´í„°ë„ í™œìš© ê°€ëŠ¥



## í•™ìŠµ ë°ì´í„° ë¹„êµ ë° ê³µí†µì 

- **ê³µê°œì„±:**
  - ë‘ ëª¨ë¸ ëª¨ë‘ ëª¨ë“  ë°ì´í„°ì…‹ì„ ê³µê°œí•˜ì—¬, ì—°êµ¬ìë“¤ì´ ë™ì¼ ì¡°ê±´ì—ì„œ ì‹¤í—˜ ì¬í˜„ ë° ì»¤ìŠ¤í„°ë§ˆì´ì§•ì´ ê°€ëŠ¥í•˜ë„ë¡ ì§€ì›

- **ë°ì´í„° ë¯¹ì‹± ì „ëµ:**

  - TÃ¼lu 3ëŠ” í¬ìŠ¤íŠ¸ íŠ¸ë ˆì´ë‹ì„ ìœ„í•œ ë‹¨ê³„ë³„ ë°ì´í„° íë ˆì´ì…˜ì— ì§‘ì¤‘

  - SmolLM2ëŠ” ëŒ€ê·œëª¨ Pre-training ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì–¸ì–´ ëª¨ë¸ì˜ ë²”ìš©ì„±ì„ ê·¹ëŒ€í™”í•œ í›„, íƒœìŠ¤í¬ë³„ Fine-tuning ë°ì´í„°ë¡œ ì„±ëŠ¥ì„ ë³´ì™„

- **ëª©í‘œ:**
  - ë‘ ëª¨ë¸ ëª¨ë‘ ë‹¤ì–‘í•œ íƒœìŠ¤í¬ë¥¼ ì»¤ë²„í•˜ê¸° ìœ„í•´, ì—¬ëŸ¬ ë„ë©”ì¸ê³¼ ë¬¸ì²´ì˜ ë°ì´í„°ë¥¼ í˜¼í•©í•˜ëŠ” ì „ëµì„ ì·¨í•¨



# Train Pipelines & Hyper-Parameters

**TÃ¼lu 3**ì™€ **SmolLM2**ì˜ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ë° í•˜ì´í¼ íŒŒë¼ë¯¸í„°ì— ëŒ€í•´ ì•Œì•„ë³¸ë‹¤.



## TÃ¼lu 3

**í•™ìŠµ ë‹¨ê³„:**

- **Supervised Finetuning (SFT):**

  - **Optimizer:** AdamW (Î²â‚=0.9, Î²â‚‚=0.999, Îµ=1Ã—10â»â¸)

  - **Learning Rate:** 8B/70BëŠ” 3Ã—10â»âµ, 405BëŠ” 1Ã—10â»âµ

  - **Batch Size:** 8B/70BëŠ” 512 (gradient accumulation ì ìš©), 405BëŠ” 256

  - **Warmup Steps:** 8B/70B: 500 steps, 405B: 1,000 steps

  - **Total Steps:** 8B: 10,000, 70B: 15,000, 405B: 20,000

- **Preference Tuning(DPO):**

  - **Learning Rate:** 1Ã—10â»âµ

  - **Batch Size:** 256

  - **Total Steps:** 5,000

  - **Temperature (Ï„):** 0.1, **Regularization:** 0.01

- **Reinforcement Learning with Verifiable Rewards (RLVR, PPO, 8B ì „ìš©):**

  - **Algorithm:** PPO ê¸°ë°˜ RLVR

  - **Learning Rate:** 1Ã—10â»â¶

  - **Batch Size:** 128 sequences/update

  - **Clip Range:** 0.2, **Value Function Coefficient:** 0.5, **Entropy Coefficient:** 0.01

  - **Total Steps:** 5,000

  - **ì¶”ê°€:** Reward Model í•™ìŠµ (Learning Rate: 2Ã—10â»âµ, Batch Size: 256, 3,000 steps)



## SmolLM2

**í•™ìŠµ ë‹¨ê³„:**

- **Pre-training:**

  - **Optimizer:** AdamW (Î²â‚ = 0.9, Î²â‚‚ = 0.98, Îµ = 1e-9)

  - **Learning Rate:** 1Ã—10â»â´ (ì„ í˜• warmup í›„ cosine decay)

  - **Batch Size:** 512 sequences (ë¶„ì‚° í•™ìŠµ ì ìš©)

  - **Warmup Steps:** 2,000

  - **Total Steps:** 100,000

  - **Sequence Length:** 1,024 tokens

  - **Dropout:** 0.1, **Weight Decay:** 0.01

  - **Checkpoint:** ë§¤ 5,000 steps ì €ì¥

- **Supervised Finetuning (SFT):**

  - **Optimizer:** AdamW (Pre-trainingê³¼ ìœ ì‚¬ ì„¤ì •)

  - **Learning Rate:** 3Ã—10â»âµ

  - **Batch Size:** 256

  - **Warmup Steps:** 500

  - **Total Steps:** 10,000

  - **Sequence Length:** 1,024 tokens

  - **Dropout:** 0.1, **Weight Decay:** 0.1

  - **Checkpoint:** ë§¤ 1,000 steps ì €ì¥

- **Preference Tuning(DPO, Optional):**
  - **Temperature:** 0.1
  - **Regularization:** 0.01
  - **Steps**: 5,000



## ë¹„êµ ë° ì¸ì‚¬ì´íŠ¸

- **TÃ¼lu 3:**

  - Llama 3.1 ê¸°ë°˜ì˜ ëª¨ë¸ì— ëŒ€í•´ í›„ì²˜ë¦¬(post-training)ë¡œ SFT, Preference íŠœë‹, RLVR ë‹¨ê³„ë¥¼ ì ìš©

  - ëª¨ë¸ í¬ê¸°ì— ë”°ë¥¸ ì„¸ë°€í•œ íŒŒë¼ë¯¸í„° ì¡°ì •ì´ ë‹ë³´ì„

- **SmolLM2:**

  - Pre-trainingë¶€í„° ì‹œì‘í•˜ì—¬, ëŒ€ê·œëª¨ ë°ì´í„°ë¡œ ë²”ìš© ì–¸ì–´ ëª¨ë¸ì„ êµ¬ì¶•í•œ í›„ Fine-tuningìœ¼ë¡œ íŠ¹ì • íƒœìŠ¤í¬ì— ë§ì¶¤

  - Pre-training ë‹¨ê³„ì˜ ë°ì´í„° ê·œëª¨(ì•½ 50B í† í°)ì™€ ê¸´ í•™ìŠµ ìŠ¤í…ì´ íŠ¹ì§•

- **ê³µí†µì :**

  - ëª¨ë“  ë‹¨ê³„ì—ì„œ AdamW optimizer ì‚¬ìš©, warm up ë° weight decay ì ìš©

  - í•™ìŠµ ë°ì´í„°ì™€ í•˜ì´í¼ íŒŒë¼ë¯¸í„°ê°€ ì „ ê³¼ì • ê³µê°œë˜ì–´ ìˆìŒ

  - ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ì‚¬ì´ì¦ˆ, ê° í•™ìŠµ ë‹¨ê³„ì— ë”°ë¼ í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì¡°ì •ì´ ìˆìŒ



# Model Checkpoints Information

**TÃ¼lu 3**ì™€ **SmolLM2**ì˜ ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ë“¤ì„ ê¸°ë¡í•¨.



## TÃ¼lu 3

- **8B:**

  - SFT: `allenai/Llama-3.1-Tulu-3-8B-SFT`

  - DPO: `allenai/Llama-3.1-Tulu-3-8B-DPO`

  - RLVR ìµœì¢…: `allenai/Llama-3.1-Tulu-3-8B`

  - ë³´ìƒ ëª¨ë¸(RM): `allenai/Llama-3.1-Tulu-3-8B-RM`

- **70B:**

  - SFT: `allenai/Llama-3.1-Tulu-3-70B-SFT`

  - DPO: `allenai/Llama-3.1-Tulu-3-70B-DPO`

  - ìµœì¢… ëª¨ë¸: `allenai/Llama-3.1-Tulu-3-70B`

- **405B:**

  - SFT: `allenai/Llama-3.1-Tulu-3-405B-SFT`

  - DPO ìµœì¢…: `allenai/Llama-3.1-Tulu-3-405B`



## SmolLM2

- **135M:**

  - Base: `HuggingFaceTB/SmolLM2-135M`

  - Instruct: `HuggingFaceTB/SmolLM2-135M-Instruct`

- **360M:**

  - Base: `HuggingFaceTB/SmolLM2-360M`

  - Instruct: `HuggingFaceTB/SmolLM2-360M-Instruct`

- **1.7B:**

  - Base: `HuggingFaceTB/SmolLM2-1.7B`

  - Instruct: `HuggingFaceTB/SmolLM2-1.7B-Instruct`




# ìš”ì•½ ë° ê²°ë¡ 

TÃ¼lu 3ì™€ SmolLM2 ëª¨ë‘ ë°ì´í„° íˆ¬ëª…ì„±ê³¼ ì„¸ë°€í•œ í•™ìŠµ ë ˆì‹œí”¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¬í˜„ ê°€ëŠ¥í•˜ê³  í™•ì¥ì„±ì´ ë›°ì–´ë‚œ ëª¨ë¸ êµ¬ì¶• ì‚¬ë¡€ë‹¤.

- **TÃ¼lu 3:** Llama 3.1 ê¸°ë°˜ í¬ìŠ¤íŠ¸ íŠ¸ë ˆì´ë‹ ëª¨ë¸ë¡œ, SFT, DPO, RLVR ë‹¨ê³„ë¥¼ í†µí•´ ìµœì¢… ëª¨ë¸ ì™„ì„±
- **SmolLM2:** Llama architecture ê¸°ë°˜ ëª¨ë¸ë¡œ, Pre-train, task ë³„ SFTë¥¼ í†µí•´ ìµœì¢… ëª¨ë¸ ì™„ì„±



ì•ìœ¼ë¡œë„ ì´ëŸ¬í•œ ê³µê°œ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ì–‘í•œ ì‹¤í—˜ê³¼ ì—°êµ¬ê°€ ì´ë£¨ì–´ì§€ê¸¸ ê¸°ëŒ€í•œë‹¤.

ë˜í•œ, ë‘ ëª¨ë¸ì˜ ë ˆì‹œí”¼ë¥¼ ì‹¤ì œ í•™ìŠµì— ì ìš©í•´ë³´ëŠ” ê²½í—˜ì´ í° ë„ì›€ì´ ë  ê²ƒì´ë¼ ë¯¿ëŠ”ë‹¤.

